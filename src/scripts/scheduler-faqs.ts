import pool from '../lib/db';
import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY || '' });

async function generarFaqsSugeridas() {
    const { rows: preguntas } = await pool.query(`
        SELECT * FROM faq_sugeridas
        WHERE veces_repetida >= 3 AND procesada = false AND canal IS NOT NULL
        LIMIT 10
      `);      

  for (const p of preguntas) {
    let canal = (p.canal || '').toLowerCase();
let estilo = '';

if (canal === 'voz') {
  estilo = 'Tu respuesta serÃ¡ hablada, asÃ­ que evita frases largas o tÃ©cnicas. SÃ© claro, directo y cÃ¡lido.';
} else if (canal === 'facebook' || canal === 'instagram') {
  estilo = 'El cliente estÃ¡ escribiendo por redes sociales. Usa un tono amigable, informal pero profesional.';
} else {
  estilo = 'El cliente estÃ¡ en WhatsApp. SÃ© breve, directo y cordial.';
}

const prompt = `Un cliente ha preguntado frecuentemente: "${p.pregunta}". ${estilo} Responde de forma Ãºtil como si fueras el asistente del negocio.`;

    try {
      const respuesta = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          { role: 'system', content: "Eres un asistente de atenciÃ³n al cliente amigable y claro." },
          { role: 'user', content: prompt }
        ],
        temperature: 0.4,
      });

      const sugerida = respuesta.choices[0]?.message?.content?.trim();
      if (sugerida) {
        await pool.query(
          `UPDATE faq_sugeridas 
           SET respuesta_sugerida = $1, procesada = true
           WHERE id = $2`,
          [sugerida, p.id]
        );
        console.log(`âœ… FAQ generada para: "${p.pregunta}"`);
      }
    } catch (err) {
      console.error(`âŒ Error generando respuesta para "${p.pregunta}":`, err);
    }
  }
}

generarFaqsSugeridas().then(() => {
  console.log("ðŸŽ¯ Proceso completado.");
  process.exit(0);
});